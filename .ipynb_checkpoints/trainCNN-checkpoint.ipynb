{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6dc5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3bce3b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5417 images belonging to 10 classes.\n",
      "Found 400 images belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3000x2000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64, 3)\n",
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "train_path = r'E:\\VIT\\5 sem\\CSE3016 - Computer Graphics & Multimedia\\project\\Sign Language Interpreter (Final)\\gesture\\train'\n",
    "test_path = r'E:\\VIT\\5 sem\\CSE3016 - Computer Graphics & Multimedia\\project\\Sign Language Interpreter (Final)\\gesture\\test'\n",
    "\n",
    "# TESTING OF ONLY ONE IMAGE\n",
    "\n",
    "# train_path = r'E:\\VIT\\5 sem\\CSE3016 - Computer Graphics & Multimedia\\project\\data_flair_code\\gesture\\img_train'\n",
    "# test_path = r'E:\\VIT\\5 sem\\CSE3016 - Computer Graphics & Multimedia\\project\\data_flair_code\\gesture\\img_test'\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=10,shuffle=True)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)\n",
    "\n",
    "imgs, labels = next(train_batches)\n",
    "\n",
    "\n",
    "#Plotting the images...\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(30,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotImages(imgs)\n",
    "print(imgs.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "72ae34d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_27 (Conv2D)          (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 31, 31, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 31, 31, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 15, 15, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 13, 13, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 6, 6, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 64)                294976    \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 414,346\n",
      "Trainable params: 414,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10,activation =\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1f0d7bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "# early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer=RMSprop(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.05)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7b4cfa23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "542/542 [==============================] - 26s 46ms/step - loss: 0.6685 - accuracy: 0.8191 - val_loss: 1.9497 - val_accuracy: 0.4575\n",
      "Epoch 2/20\n",
      "542/542 [==============================] - 33s 61ms/step - loss: 0.1841 - accuracy: 0.9308 - val_loss: 1.9131 - val_accuracy: 0.5175\n",
      "Epoch 3/20\n",
      "542/542 [==============================] - 33s 60ms/step - loss: 0.1377 - accuracy: 0.9450 - val_loss: 2.1224 - val_accuracy: 0.5375\n",
      "Epoch 4/20\n",
      "542/542 [==============================] - 27s 50ms/step - loss: 0.1257 - accuracy: 0.9494 - val_loss: 2.0779 - val_accuracy: 0.5350\n",
      "Epoch 5/20\n",
      "542/542 [==============================] - 28s 53ms/step - loss: 0.1144 - accuracy: 0.9526 - val_loss: 2.0862 - val_accuracy: 0.5600\n",
      "Epoch 6/20\n",
      "542/542 [==============================] - 28s 51ms/step - loss: 0.1122 - accuracy: 0.9502 - val_loss: 2.1179 - val_accuracy: 0.5950\n",
      "Epoch 7/20\n",
      "542/542 [==============================] - 24s 45ms/step - loss: 0.1053 - accuracy: 0.9531 - val_loss: 2.0926 - val_accuracy: 0.5900\n",
      "Epoch 8/20\n",
      "542/542 [==============================] - 24s 43ms/step - loss: 0.1059 - accuracy: 0.9535 - val_loss: 2.3147 - val_accuracy: 0.5900\n",
      "Epoch 9/20\n",
      "542/542 [==============================] - 25s 46ms/step - loss: 0.1011 - accuracy: 0.9553 - val_loss: 2.1149 - val_accuracy: 0.6050\n",
      "Epoch 10/20\n",
      "542/542 [==============================] - 25s 47ms/step - loss: 0.1005 - accuracy: 0.9548 - val_loss: 2.2688 - val_accuracy: 0.6100\n",
      "Epoch 11/20\n",
      "542/542 [==============================] - 26s 48ms/step - loss: 0.0935 - accuracy: 0.9574 - val_loss: 2.4687 - val_accuracy: 0.6275\n",
      "Epoch 12/20\n",
      "542/542 [==============================] - 29s 53ms/step - loss: 0.0928 - accuracy: 0.9574 - val_loss: 2.2641 - val_accuracy: 0.6100\n",
      "Epoch 13/20\n",
      "542/542 [==============================] - 30s 56ms/step - loss: 0.0985 - accuracy: 0.9544 - val_loss: 2.4801 - val_accuracy: 0.6300\n",
      "Epoch 14/20\n",
      "542/542 [==============================] - 31s 57ms/step - loss: 0.0914 - accuracy: 0.9581 - val_loss: 2.6002 - val_accuracy: 0.6225\n",
      "Epoch 15/20\n",
      "542/542 [==============================] - 30s 56ms/step - loss: 0.0868 - accuracy: 0.9598 - val_loss: 2.4315 - val_accuracy: 0.6300\n",
      "Epoch 16/20\n",
      "542/542 [==============================] - 31s 57ms/step - loss: 0.0922 - accuracy: 0.9575 - val_loss: 2.7229 - val_accuracy: 0.5525\n",
      "Epoch 17/20\n",
      "542/542 [==============================] - 30s 56ms/step - loss: 0.0892 - accuracy: 0.9579 - val_loss: 2.5634 - val_accuracy: 0.5650\n",
      "Epoch 18/20\n",
      "542/542 [==============================] - 30s 56ms/step - loss: 0.0905 - accuracy: 0.9559 - val_loss: 2.3625 - val_accuracy: 0.5825\n",
      "Epoch 19/20\n",
      "542/542 [==============================] - 30s 56ms/step - loss: 0.0885 - accuracy: 0.9588 - val_loss: 2.3915 - val_accuracy: 0.6000\n",
      "Epoch 20/20\n",
      "542/542 [==============================] - 30s 55ms/step - loss: 0.0879 - accuracy: 0.9596 - val_loss: 2.4883 - val_accuracy: 0.6225\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(train_batches, epochs=20,  validation_data = test_batches)#, checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "35398cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0764 - accuracy: 0.9000\n",
      "loss of 1.0763587951660156; accuracy of 89.99999761581421%\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = next(test_batches) # For getting next batch of imgs...\n",
    "scores = model.evaluate(imgs, labels, verbose=1)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "\n",
    "model.save('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3b84aa97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions on a small set of test data--\n",
      "\n",
      "Nine   Six   Five   Two   Nine   Nine   Nine   One   Seven   Nine   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3000x2000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual labels\n",
      "Nine   Six   Five   Four   Nine   Nine   Nine   One   Seven   Nine   (10, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "# imgs, labels = next(test_batches)\n",
    "\n",
    "# model = keras.models.load_model(r\"best_model.h5\")\n",
    "\n",
    "# scores = model.evaluate(imgs, labels, verbose=0)\n",
    "# print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# scores #[loss, accuracy] on test data...\n",
    "# model.metrics_names\n",
    "\n",
    "\n",
    "word_dict = {0:'One',1:'Ten',2:'Two',3:'Three',4:'Four',5:'Five',6:'Six',7:'Seven',8:'Eight',9:'Nine'}\n",
    "\n",
    "predictions = model.predict(imgs, verbose=0)\n",
    "print(\"predictions on a small set of test data--\")\n",
    "print(\"\")\n",
    "for ind, i in enumerate(predictions):\n",
    "    print(word_dict[np.argmax(i)], end='   ')\n",
    "\n",
    "plotImages(imgs)\n",
    "print('Actual labels')\n",
    "for i in labels:\n",
    "    print(word_dict[np.argmax(i)], end='   ')\n",
    "\n",
    "print(imgs.shape)\n",
    "\n",
    "# history2.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf74cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
